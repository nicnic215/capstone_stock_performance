{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/Geoffrey/anaconda3/envs/FTDS/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, classification_report, confusion_matrix, r2_score, mean_absolute_error, mean_squared_error, median_absolute_error\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.base import clone\n",
    "import catboost as catb\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_full[\"SHARPE\"]\n",
    "X = df_full.drop(columns=\"SHARPE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "scaler = Normalizer()\n",
    "normalizedX = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walkforward_model(normalizedX,y,algo):\n",
    "    recalc_dates = normalizedX.resample('BM',level='date').mean().index.values[:-1]\n",
    "    \n",
    "    ## Train models\n",
    "    models_rolling_window = pd.Series(index=recalc_dates)\n",
    "    for date in recalc_dates:    \n",
    "        X_train = normalizedX.xs(slice(date-pd.Timedelta('3652 days'),date),level='date',drop_level=False)\n",
    "        y_train = y.xs(slice(date-pd.Timedelta('3652 days'),date),level='date',drop_level=False)\n",
    "        print(f'Train with data prior to: {date} ({y_train.count()} obs)')\n",
    "        \n",
    "        model = clone(algo)\n",
    "        model.fit(X_train,y_train)\n",
    "        models_rolling_window.loc[date] = model\n",
    "\n",
    "    begin_dates = models_rolling_window.index\n",
    "    end_dates = models_rolling_window.index[1:].append(pd.to_datetime(['2099-12-31']))\n",
    "\n",
    "    ## Generate OUT OF SAMPLE walk-forward predictions\n",
    "    predictions_rolling_window = pd.Series(index=normalizedX.index)\n",
    "    for i,model in enumerate(models_rolling_window): #loop thru each models object in collection\n",
    "        print(f'Using model trained on {begin_dates[i]}, Predict from: {begin_dates[i]} to: {end_dates[i]}')\n",
    "        X = normalizedX.xs(slice(begin_dates[i],end_dates[i]),level='date',drop_level=False)\n",
    "        p = pd.Series(model.predict(X),index=X.index)\n",
    "        predictions_rolling_window.loc[X.index] = p\n",
    "    \n",
    "    return models_rolling_window,predictions_rolling_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train with data prior to: 2000-01-31T00:00:00.000000000 (19 obs)\n",
      "Train with data prior to: 2000-02-29T00:00:00.000000000 (38 obs)\n",
      "Train with data prior to: 2000-03-31T00:00:00.000000000 (57 obs)\n",
      "Train with data prior to: 2000-04-28T00:00:00.000000000 (76 obs)\n",
      "Train with data prior to: 2000-05-31T00:00:00.000000000 (95 obs)\n",
      "Train with data prior to: 2000-06-30T00:00:00.000000000 (114 obs)\n",
      "Train with data prior to: 2000-07-31T00:00:00.000000000 (133 obs)\n",
      "Train with data prior to: 2000-08-31T00:00:00.000000000 (152 obs)\n",
      "Train with data prior to: 2000-09-29T00:00:00.000000000 (171 obs)\n",
      "Train with data prior to: 2000-10-31T00:00:00.000000000 (190 obs)\n",
      "Train with data prior to: 2000-11-30T00:00:00.000000000 (209 obs)\n",
      "Train with data prior to: 2000-12-29T00:00:00.000000000 (229 obs)\n",
      "Train with data prior to: 2001-01-31T00:00:00.000000000 (249 obs)\n",
      "Train with data prior to: 2001-02-28T00:00:00.000000000 (269 obs)\n",
      "Train with data prior to: 2001-03-30T00:00:00.000000000 (289 obs)\n",
      "Train with data prior to: 2001-04-30T00:00:00.000000000 (309 obs)\n",
      "Train with data prior to: 2001-05-31T00:00:00.000000000 (329 obs)\n",
      "Train with data prior to: 2001-06-29T00:00:00.000000000 (349 obs)\n",
      "Train with data prior to: 2001-07-31T00:00:00.000000000 (369 obs)\n",
      "Train with data prior to: 2001-08-31T00:00:00.000000000 (389 obs)\n",
      "Train with data prior to: 2001-09-28T00:00:00.000000000 (409 obs)\n",
      "Train with data prior to: 2001-10-31T00:00:00.000000000 (429 obs)\n",
      "Train with data prior to: 2001-11-30T00:00:00.000000000 (449 obs)\n",
      "Train with data prior to: 2001-12-31T00:00:00.000000000 (469 obs)\n",
      "Train with data prior to: 2002-01-31T00:00:00.000000000 (489 obs)\n",
      "Train with data prior to: 2002-02-28T00:00:00.000000000 (509 obs)\n",
      "Train with data prior to: 2002-03-29T00:00:00.000000000 (509 obs)\n",
      "Train with data prior to: 2002-04-30T00:00:00.000000000 (529 obs)\n",
      "Train with data prior to: 2002-05-31T00:00:00.000000000 (549 obs)\n",
      "Train with data prior to: 2002-06-28T00:00:00.000000000 (569 obs)\n",
      "Train with data prior to: 2002-07-31T00:00:00.000000000 (589 obs)\n",
      "Train with data prior to: 2002-08-30T00:00:00.000000000 (609 obs)\n",
      "Train with data prior to: 2002-09-30T00:00:00.000000000 (629 obs)\n",
      "Train with data prior to: 2002-10-31T00:00:00.000000000 (649 obs)\n",
      "Train with data prior to: 2002-11-29T00:00:00.000000000 (669 obs)\n",
      "Train with data prior to: 2002-12-31T00:00:00.000000000 (689 obs)\n",
      "Train with data prior to: 2003-01-31T00:00:00.000000000 (709 obs)\n",
      "Train with data prior to: 2003-02-28T00:00:00.000000000 (729 obs)\n",
      "Train with data prior to: 2003-03-31T00:00:00.000000000 (749 obs)\n",
      "Train with data prior to: 2003-04-30T00:00:00.000000000 (769 obs)\n",
      "Train with data prior to: 2003-05-30T00:00:00.000000000 (789 obs)\n",
      "Train with data prior to: 2003-06-30T00:00:00.000000000 (809 obs)\n",
      "Train with data prior to: 2003-07-31T00:00:00.000000000 (829 obs)\n",
      "Train with data prior to: 2003-08-29T00:00:00.000000000 (849 obs)\n",
      "Train with data prior to: 2003-09-30T00:00:00.000000000 (869 obs)\n",
      "Train with data prior to: 2003-10-31T00:00:00.000000000 (889 obs)\n",
      "Train with data prior to: 2003-11-28T00:00:00.000000000 (909 obs)\n",
      "Train with data prior to: 2003-12-31T00:00:00.000000000 (929 obs)\n",
      "Train with data prior to: 2004-01-30T00:00:00.000000000 (949 obs)\n",
      "Train with data prior to: 2004-02-27T00:00:00.000000000 (969 obs)\n",
      "Train with data prior to: 2004-03-31T00:00:00.000000000 (989 obs)\n",
      "Train with data prior to: 2004-04-30T00:00:00.000000000 (1009 obs)\n",
      "Train with data prior to: 2004-05-31T00:00:00.000000000 (1009 obs)\n",
      "Train with data prior to: 2004-06-30T00:00:00.000000000 (1029 obs)\n",
      "Train with data prior to: 2004-07-30T00:00:00.000000000 (1049 obs)\n",
      "Train with data prior to: 2004-08-31T00:00:00.000000000 (1069 obs)\n",
      "Train with data prior to: 2004-09-30T00:00:00.000000000 (1089 obs)\n",
      "Train with data prior to: 2004-10-29T00:00:00.000000000 (1109 obs)\n",
      "Train with data prior to: 2004-11-30T00:00:00.000000000 (1129 obs)\n",
      "Train with data prior to: 2004-12-31T00:00:00.000000000 (1149 obs)\n",
      "Train with data prior to: 2005-01-31T00:00:00.000000000 (1169 obs)\n",
      "Train with data prior to: 2005-02-28T00:00:00.000000000 (1189 obs)\n",
      "Train with data prior to: 2005-03-31T00:00:00.000000000 (1209 obs)\n",
      "Train with data prior to: 2005-04-29T00:00:00.000000000 (1229 obs)\n",
      "Train with data prior to: 2005-05-31T00:00:00.000000000 (1249 obs)\n",
      "Train with data prior to: 2005-06-30T00:00:00.000000000 (1269 obs)\n",
      "Train with data prior to: 2005-07-29T00:00:00.000000000 (1289 obs)\n",
      "Train with data prior to: 2005-08-31T00:00:00.000000000 (1309 obs)\n",
      "Train with data prior to: 2005-09-30T00:00:00.000000000 (1329 obs)\n",
      "Train with data prior to: 2005-10-31T00:00:00.000000000 (1349 obs)\n",
      "Train with data prior to: 2005-11-30T00:00:00.000000000 (1369 obs)\n",
      "Train with data prior to: 2005-12-30T00:00:00.000000000 (1389 obs)\n",
      "Train with data prior to: 2006-01-31T00:00:00.000000000 (1409 obs)\n",
      "Train with data prior to: 2006-02-28T00:00:00.000000000 (1429 obs)\n",
      "Train with data prior to: 2006-03-31T00:00:00.000000000 (1449 obs)\n",
      "Train with data prior to: 2006-04-28T00:00:00.000000000 (1469 obs)\n",
      "Train with data prior to: 2006-05-31T00:00:00.000000000 (1489 obs)\n",
      "Train with data prior to: 2006-06-30T00:00:00.000000000 (1509 obs)\n",
      "Train with data prior to: 2006-07-31T00:00:00.000000000 (1529 obs)\n",
      "Train with data prior to: 2006-08-31T00:00:00.000000000 (1549 obs)\n",
      "Train with data prior to: 2006-09-29T00:00:00.000000000 (1569 obs)\n",
      "Train with data prior to: 2006-10-31T00:00:00.000000000 (1589 obs)\n",
      "Train with data prior to: 2006-11-30T00:00:00.000000000 (1609 obs)\n",
      "Train with data prior to: 2006-12-29T00:00:00.000000000 (1629 obs)\n",
      "Train with data prior to: 2007-01-31T00:00:00.000000000 (1649 obs)\n",
      "Train with data prior to: 2007-02-28T00:00:00.000000000 (1669 obs)\n",
      "Train with data prior to: 2007-03-30T00:00:00.000000000 (1689 obs)\n",
      "Train with data prior to: 2007-04-30T00:00:00.000000000 (1709 obs)\n",
      "Train with data prior to: 2007-05-31T00:00:00.000000000 (1729 obs)\n",
      "Train with data prior to: 2007-06-29T00:00:00.000000000 (1749 obs)\n",
      "Train with data prior to: 2007-07-31T00:00:00.000000000 (1769 obs)\n",
      "Train with data prior to: 2007-08-31T00:00:00.000000000 (1789 obs)\n",
      "Train with data prior to: 2007-09-28T00:00:00.000000000 (1809 obs)\n",
      "Train with data prior to: 2007-10-31T00:00:00.000000000 (1829 obs)\n",
      "Train with data prior to: 2007-11-30T00:00:00.000000000 (1849 obs)\n",
      "Train with data prior to: 2007-12-31T00:00:00.000000000 (1869 obs)\n",
      "Train with data prior to: 2008-01-31T00:00:00.000000000 (1889 obs)\n",
      "Train with data prior to: 2008-02-29T00:00:00.000000000 (1909 obs)\n",
      "Train with data prior to: 2008-03-31T00:00:00.000000000 (1929 obs)\n",
      "Train with data prior to: 2008-04-30T00:00:00.000000000 (1949 obs)\n",
      "Train with data prior to: 2008-05-30T00:00:00.000000000 (1969 obs)\n",
      "Train with data prior to: 2008-06-30T00:00:00.000000000 (1989 obs)\n",
      "Train with data prior to: 2008-07-31T00:00:00.000000000 (2009 obs)\n",
      "Train with data prior to: 2008-08-29T00:00:00.000000000 (2029 obs)\n",
      "Train with data prior to: 2008-09-30T00:00:00.000000000 (2049 obs)\n",
      "Train with data prior to: 2008-10-31T00:00:00.000000000 (2069 obs)\n",
      "Train with data prior to: 2008-11-28T00:00:00.000000000 (2089 obs)\n",
      "Train with data prior to: 2008-12-31T00:00:00.000000000 (2109 obs)\n",
      "Train with data prior to: 2009-01-30T00:00:00.000000000 (2129 obs)\n",
      "Train with data prior to: 2009-02-27T00:00:00.000000000 (2149 obs)\n",
      "Train with data prior to: 2009-03-31T00:00:00.000000000 (2169 obs)\n",
      "Train with data prior to: 2009-04-30T00:00:00.000000000 (2189 obs)\n",
      "Train with data prior to: 2009-05-29T00:00:00.000000000 (2209 obs)\n",
      "Train with data prior to: 2009-06-30T00:00:00.000000000 (2229 obs)\n",
      "Train with data prior to: 2009-07-31T00:00:00.000000000 (2249 obs)\n",
      "Train with data prior to: 2009-08-31T00:00:00.000000000 (2269 obs)\n",
      "Train with data prior to: 2009-09-30T00:00:00.000000000 (2289 obs)\n",
      "Train with data prior to: 2009-10-30T00:00:00.000000000 (2309 obs)\n",
      "Train with data prior to: 2009-11-30T00:00:00.000000000 (2329 obs)\n",
      "Train with data prior to: 2009-12-31T00:00:00.000000000 (2349 obs)\n",
      "Train with data prior to: 2010-01-29T00:00:00.000000000 (2369 obs)\n",
      "Train with data prior to: 2010-02-26T00:00:00.000000000 (2370 obs)\n",
      "Train with data prior to: 2010-03-31T00:00:00.000000000 (2371 obs)\n",
      "Train with data prior to: 2010-04-30T00:00:00.000000000 (2353 obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train with data prior to: 2010-05-31T00:00:00.000000000 (2353 obs)\n",
      "Train with data prior to: 2010-06-30T00:00:00.000000000 (2354 obs)\n",
      "Train with data prior to: 2010-07-30T00:00:00.000000000 (2355 obs)\n",
      "Train with data prior to: 2010-08-31T00:00:00.000000000 (2356 obs)\n",
      "Train with data prior to: 2010-09-30T00:00:00.000000000 (2338 obs)\n",
      "Train with data prior to: 2010-10-29T00:00:00.000000000 (2358 obs)\n",
      "Train with data prior to: 2010-11-30T00:00:00.000000000 (2359 obs)\n",
      "Train with data prior to: 2010-12-31T00:00:00.000000000 (2340 obs)\n",
      "Train with data prior to: 2011-01-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2011-02-28T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2011-03-31T00:00:00.000000000 (2340 obs)\n",
      "Train with data prior to: 2011-04-29T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2011-05-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2011-06-30T00:00:00.000000000 (2340 obs)\n",
      "Train with data prior to: 2011-07-29T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2011-08-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2011-09-30T00:00:00.000000000 (2340 obs)\n",
      "Train with data prior to: 2011-10-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2011-11-30T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2011-12-30T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2012-01-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2012-02-29T00:00:00.000000000 (2340 obs)\n",
      "Train with data prior to: 2012-03-30T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2012-04-30T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2012-05-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2012-06-29T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2012-07-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2012-08-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2012-09-28T00:00:00.000000000 (2380 obs)\n",
      "Train with data prior to: 2012-10-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2012-11-30T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2012-12-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2013-01-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2013-02-28T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2013-03-29T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2013-04-30T00:00:00.000000000 (2340 obs)\n",
      "Train with data prior to: 2013-05-31T00:00:00.000000000 (2340 obs)\n",
      "Train with data prior to: 2013-06-28T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2013-07-31T00:00:00.000000000 (2340 obs)\n",
      "Train with data prior to: 2013-08-30T00:00:00.000000000 (2340 obs)\n",
      "Train with data prior to: 2013-09-30T00:00:00.000000000 (2340 obs)\n",
      "Train with data prior to: 2013-10-31T00:00:00.000000000 (2340 obs)\n",
      "Train with data prior to: 2013-11-29T00:00:00.000000000 (2340 obs)\n",
      "Train with data prior to: 2013-12-31T00:00:00.000000000 (2340 obs)\n",
      "Train with data prior to: 2014-01-31T00:00:00.000000000 (2340 obs)\n",
      "Train with data prior to: 2014-02-28T00:00:00.000000000 (2340 obs)\n",
      "Train with data prior to: 2014-03-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2014-04-30T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2014-05-30T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2014-06-30T00:00:00.000000000 (2380 obs)\n",
      "Train with data prior to: 2014-07-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2014-08-29T00:00:00.000000000 (2380 obs)\n",
      "Train with data prior to: 2014-09-30T00:00:00.000000000 (2380 obs)\n",
      "Train with data prior to: 2014-10-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2014-11-28T00:00:00.000000000 (2380 obs)\n",
      "Train with data prior to: 2014-12-31T00:00:00.000000000 (2380 obs)\n",
      "Train with data prior to: 2015-01-30T00:00:00.000000000 (2380 obs)\n",
      "Train with data prior to: 2015-02-27T00:00:00.000000000 (2380 obs)\n",
      "Train with data prior to: 2015-03-31T00:00:00.000000000 (2380 obs)\n",
      "Train with data prior to: 2015-04-30T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2015-05-29T00:00:00.000000000 (2380 obs)\n",
      "Train with data prior to: 2015-06-30T00:00:00.000000000 (2380 obs)\n",
      "Train with data prior to: 2015-07-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2015-08-31T00:00:00.000000000 (2380 obs)\n",
      "Train with data prior to: 2015-09-30T00:00:00.000000000 (2380 obs)\n",
      "Train with data prior to: 2015-10-30T00:00:00.000000000 (2380 obs)\n",
      "Train with data prior to: 2015-11-30T00:00:00.000000000 (2380 obs)\n",
      "Train with data prior to: 2015-12-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2016-01-29T00:00:00.000000000 (2380 obs)\n",
      "Train with data prior to: 2016-02-29T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2016-03-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2016-04-29T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2016-05-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2016-06-30T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2016-07-29T00:00:00.000000000 (2380 obs)\n",
      "Train with data prior to: 2016-08-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2016-09-30T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2016-10-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2016-11-30T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2016-12-30T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2017-01-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2017-02-28T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2017-03-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2017-04-28T00:00:00.000000000 (2380 obs)\n",
      "Train with data prior to: 2017-05-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2017-06-30T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2017-07-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2017-08-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2017-09-29T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2017-10-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2017-11-30T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2017-12-29T00:00:00.000000000 (2380 obs)\n",
      "Train with data prior to: 2018-01-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2018-02-28T00:00:00.000000000 (2380 obs)\n",
      "Train with data prior to: 2018-03-30T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2018-04-30T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2018-05-31T00:00:00.000000000 (2340 obs)\n",
      "Train with data prior to: 2018-06-29T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2018-07-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2018-08-31T00:00:00.000000000 (2340 obs)\n",
      "Train with data prior to: 2018-09-28T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2018-10-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2018-11-30T00:00:00.000000000 (2340 obs)\n",
      "Train with data prior to: 2018-12-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2019-01-31T00:00:00.000000000 (2340 obs)\n",
      "Train with data prior to: 2019-02-28T00:00:00.000000000 (2340 obs)\n",
      "Train with data prior to: 2019-03-29T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2019-04-30T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2019-05-31T00:00:00.000000000 (2340 obs)\n",
      "Train with data prior to: 2019-06-28T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2019-07-31T00:00:00.000000000 (2360 obs)\n",
      "Train with data prior to: 2019-08-30T00:00:00.000000000 (2359 obs)\n",
      "Using model trained on 2000-01-31 00:00:00, Predict from: 2000-01-31 00:00:00 to: 2000-02-29 00:00:00\n",
      "Using model trained on 2000-02-29 00:00:00, Predict from: 2000-02-29 00:00:00 to: 2000-03-31 00:00:00\n",
      "Using model trained on 2000-03-31 00:00:00, Predict from: 2000-03-31 00:00:00 to: 2000-04-28 00:00:00\n",
      "Using model trained on 2000-04-28 00:00:00, Predict from: 2000-04-28 00:00:00 to: 2000-05-31 00:00:00\n",
      "Using model trained on 2000-05-31 00:00:00, Predict from: 2000-05-31 00:00:00 to: 2000-06-30 00:00:00\n",
      "Using model trained on 2000-06-30 00:00:00, Predict from: 2000-06-30 00:00:00 to: 2000-07-31 00:00:00\n",
      "Using model trained on 2000-07-31 00:00:00, Predict from: 2000-07-31 00:00:00 to: 2000-08-31 00:00:00\n",
      "Using model trained on 2000-08-31 00:00:00, Predict from: 2000-08-31 00:00:00 to: 2000-09-29 00:00:00\n",
      "Using model trained on 2000-09-29 00:00:00, Predict from: 2000-09-29 00:00:00 to: 2000-10-31 00:00:00\n",
      "Using model trained on 2000-10-31 00:00:00, Predict from: 2000-10-31 00:00:00 to: 2000-11-30 00:00:00\n",
      "Using model trained on 2000-11-30 00:00:00, Predict from: 2000-11-30 00:00:00 to: 2000-12-29 00:00:00\n",
      "Using model trained on 2000-12-29 00:00:00, Predict from: 2000-12-29 00:00:00 to: 2001-01-31 00:00:00\n",
      "Using model trained on 2001-01-31 00:00:00, Predict from: 2001-01-31 00:00:00 to: 2001-02-28 00:00:00\n",
      "Using model trained on 2001-02-28 00:00:00, Predict from: 2001-02-28 00:00:00 to: 2001-03-30 00:00:00\n",
      "Using model trained on 2001-03-30 00:00:00, Predict from: 2001-03-30 00:00:00 to: 2001-04-30 00:00:00\n",
      "Using model trained on 2001-04-30 00:00:00, Predict from: 2001-04-30 00:00:00 to: 2001-05-31 00:00:00\n",
      "Using model trained on 2001-05-31 00:00:00, Predict from: 2001-05-31 00:00:00 to: 2001-06-29 00:00:00\n",
      "Using model trained on 2001-06-29 00:00:00, Predict from: 2001-06-29 00:00:00 to: 2001-07-31 00:00:00\n",
      "Using model trained on 2001-07-31 00:00:00, Predict from: 2001-07-31 00:00:00 to: 2001-08-31 00:00:00\n",
      "Using model trained on 2001-08-31 00:00:00, Predict from: 2001-08-31 00:00:00 to: 2001-09-28 00:00:00\n",
      "Using model trained on 2001-09-28 00:00:00, Predict from: 2001-09-28 00:00:00 to: 2001-10-31 00:00:00\n",
      "Using model trained on 2001-10-31 00:00:00, Predict from: 2001-10-31 00:00:00 to: 2001-11-30 00:00:00\n",
      "Using model trained on 2001-11-30 00:00:00, Predict from: 2001-11-30 00:00:00 to: 2001-12-31 00:00:00\n",
      "Using model trained on 2001-12-31 00:00:00, Predict from: 2001-12-31 00:00:00 to: 2002-01-31 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model trained on 2002-01-31 00:00:00, Predict from: 2002-01-31 00:00:00 to: 2002-02-28 00:00:00\n",
      "Using model trained on 2002-02-28 00:00:00, Predict from: 2002-02-28 00:00:00 to: 2002-03-29 00:00:00\n",
      "Using model trained on 2002-03-29 00:00:00, Predict from: 2002-03-29 00:00:00 to: 2002-04-30 00:00:00\n",
      "Using model trained on 2002-04-30 00:00:00, Predict from: 2002-04-30 00:00:00 to: 2002-05-31 00:00:00\n",
      "Using model trained on 2002-05-31 00:00:00, Predict from: 2002-05-31 00:00:00 to: 2002-06-28 00:00:00\n",
      "Using model trained on 2002-06-28 00:00:00, Predict from: 2002-06-28 00:00:00 to: 2002-07-31 00:00:00\n",
      "Using model trained on 2002-07-31 00:00:00, Predict from: 2002-07-31 00:00:00 to: 2002-08-30 00:00:00\n",
      "Using model trained on 2002-08-30 00:00:00, Predict from: 2002-08-30 00:00:00 to: 2002-09-30 00:00:00\n",
      "Using model trained on 2002-09-30 00:00:00, Predict from: 2002-09-30 00:00:00 to: 2002-10-31 00:00:00\n",
      "Using model trained on 2002-10-31 00:00:00, Predict from: 2002-10-31 00:00:00 to: 2002-11-29 00:00:00\n",
      "Using model trained on 2002-11-29 00:00:00, Predict from: 2002-11-29 00:00:00 to: 2002-12-31 00:00:00\n",
      "Using model trained on 2002-12-31 00:00:00, Predict from: 2002-12-31 00:00:00 to: 2003-01-31 00:00:00\n",
      "Using model trained on 2003-01-31 00:00:00, Predict from: 2003-01-31 00:00:00 to: 2003-02-28 00:00:00\n",
      "Using model trained on 2003-02-28 00:00:00, Predict from: 2003-02-28 00:00:00 to: 2003-03-31 00:00:00\n",
      "Using model trained on 2003-03-31 00:00:00, Predict from: 2003-03-31 00:00:00 to: 2003-04-30 00:00:00\n",
      "Using model trained on 2003-04-30 00:00:00, Predict from: 2003-04-30 00:00:00 to: 2003-05-30 00:00:00\n",
      "Using model trained on 2003-05-30 00:00:00, Predict from: 2003-05-30 00:00:00 to: 2003-06-30 00:00:00\n",
      "Using model trained on 2003-06-30 00:00:00, Predict from: 2003-06-30 00:00:00 to: 2003-07-31 00:00:00\n",
      "Using model trained on 2003-07-31 00:00:00, Predict from: 2003-07-31 00:00:00 to: 2003-08-29 00:00:00\n",
      "Using model trained on 2003-08-29 00:00:00, Predict from: 2003-08-29 00:00:00 to: 2003-09-30 00:00:00\n",
      "Using model trained on 2003-09-30 00:00:00, Predict from: 2003-09-30 00:00:00 to: 2003-10-31 00:00:00\n",
      "Using model trained on 2003-10-31 00:00:00, Predict from: 2003-10-31 00:00:00 to: 2003-11-28 00:00:00\n",
      "Using model trained on 2003-11-28 00:00:00, Predict from: 2003-11-28 00:00:00 to: 2003-12-31 00:00:00\n",
      "Using model trained on 2003-12-31 00:00:00, Predict from: 2003-12-31 00:00:00 to: 2004-01-30 00:00:00\n",
      "Using model trained on 2004-01-30 00:00:00, Predict from: 2004-01-30 00:00:00 to: 2004-02-27 00:00:00\n",
      "Using model trained on 2004-02-27 00:00:00, Predict from: 2004-02-27 00:00:00 to: 2004-03-31 00:00:00\n",
      "Using model trained on 2004-03-31 00:00:00, Predict from: 2004-03-31 00:00:00 to: 2004-04-30 00:00:00\n",
      "Using model trained on 2004-04-30 00:00:00, Predict from: 2004-04-30 00:00:00 to: 2004-05-31 00:00:00\n",
      "Using model trained on 2004-05-31 00:00:00, Predict from: 2004-05-31 00:00:00 to: 2004-06-30 00:00:00\n",
      "Using model trained on 2004-06-30 00:00:00, Predict from: 2004-06-30 00:00:00 to: 2004-07-30 00:00:00\n",
      "Using model trained on 2004-07-30 00:00:00, Predict from: 2004-07-30 00:00:00 to: 2004-08-31 00:00:00\n",
      "Using model trained on 2004-08-31 00:00:00, Predict from: 2004-08-31 00:00:00 to: 2004-09-30 00:00:00\n",
      "Using model trained on 2004-09-30 00:00:00, Predict from: 2004-09-30 00:00:00 to: 2004-10-29 00:00:00\n",
      "Using model trained on 2004-10-29 00:00:00, Predict from: 2004-10-29 00:00:00 to: 2004-11-30 00:00:00\n",
      "Using model trained on 2004-11-30 00:00:00, Predict from: 2004-11-30 00:00:00 to: 2004-12-31 00:00:00\n",
      "Using model trained on 2004-12-31 00:00:00, Predict from: 2004-12-31 00:00:00 to: 2005-01-31 00:00:00\n",
      "Using model trained on 2005-01-31 00:00:00, Predict from: 2005-01-31 00:00:00 to: 2005-02-28 00:00:00\n",
      "Using model trained on 2005-02-28 00:00:00, Predict from: 2005-02-28 00:00:00 to: 2005-03-31 00:00:00\n",
      "Using model trained on 2005-03-31 00:00:00, Predict from: 2005-03-31 00:00:00 to: 2005-04-29 00:00:00\n",
      "Using model trained on 2005-04-29 00:00:00, Predict from: 2005-04-29 00:00:00 to: 2005-05-31 00:00:00\n",
      "Using model trained on 2005-05-31 00:00:00, Predict from: 2005-05-31 00:00:00 to: 2005-06-30 00:00:00\n",
      "Using model trained on 2005-06-30 00:00:00, Predict from: 2005-06-30 00:00:00 to: 2005-07-29 00:00:00\n",
      "Using model trained on 2005-07-29 00:00:00, Predict from: 2005-07-29 00:00:00 to: 2005-08-31 00:00:00\n",
      "Using model trained on 2005-08-31 00:00:00, Predict from: 2005-08-31 00:00:00 to: 2005-09-30 00:00:00\n",
      "Using model trained on 2005-09-30 00:00:00, Predict from: 2005-09-30 00:00:00 to: 2005-10-31 00:00:00\n",
      "Using model trained on 2005-10-31 00:00:00, Predict from: 2005-10-31 00:00:00 to: 2005-11-30 00:00:00\n",
      "Using model trained on 2005-11-30 00:00:00, Predict from: 2005-11-30 00:00:00 to: 2005-12-30 00:00:00\n",
      "Using model trained on 2005-12-30 00:00:00, Predict from: 2005-12-30 00:00:00 to: 2006-01-31 00:00:00\n",
      "Using model trained on 2006-01-31 00:00:00, Predict from: 2006-01-31 00:00:00 to: 2006-02-28 00:00:00\n",
      "Using model trained on 2006-02-28 00:00:00, Predict from: 2006-02-28 00:00:00 to: 2006-03-31 00:00:00\n",
      "Using model trained on 2006-03-31 00:00:00, Predict from: 2006-03-31 00:00:00 to: 2006-04-28 00:00:00\n",
      "Using model trained on 2006-04-28 00:00:00, Predict from: 2006-04-28 00:00:00 to: 2006-05-31 00:00:00\n",
      "Using model trained on 2006-05-31 00:00:00, Predict from: 2006-05-31 00:00:00 to: 2006-06-30 00:00:00\n",
      "Using model trained on 2006-06-30 00:00:00, Predict from: 2006-06-30 00:00:00 to: 2006-07-31 00:00:00\n",
      "Using model trained on 2006-07-31 00:00:00, Predict from: 2006-07-31 00:00:00 to: 2006-08-31 00:00:00\n",
      "Using model trained on 2006-08-31 00:00:00, Predict from: 2006-08-31 00:00:00 to: 2006-09-29 00:00:00\n",
      "Using model trained on 2006-09-29 00:00:00, Predict from: 2006-09-29 00:00:00 to: 2006-10-31 00:00:00\n",
      "Using model trained on 2006-10-31 00:00:00, Predict from: 2006-10-31 00:00:00 to: 2006-11-30 00:00:00\n",
      "Using model trained on 2006-11-30 00:00:00, Predict from: 2006-11-30 00:00:00 to: 2006-12-29 00:00:00\n",
      "Using model trained on 2006-12-29 00:00:00, Predict from: 2006-12-29 00:00:00 to: 2007-01-31 00:00:00\n",
      "Using model trained on 2007-01-31 00:00:00, Predict from: 2007-01-31 00:00:00 to: 2007-02-28 00:00:00\n",
      "Using model trained on 2007-02-28 00:00:00, Predict from: 2007-02-28 00:00:00 to: 2007-03-30 00:00:00\n",
      "Using model trained on 2007-03-30 00:00:00, Predict from: 2007-03-30 00:00:00 to: 2007-04-30 00:00:00\n",
      "Using model trained on 2007-04-30 00:00:00, Predict from: 2007-04-30 00:00:00 to: 2007-05-31 00:00:00\n",
      "Using model trained on 2007-05-31 00:00:00, Predict from: 2007-05-31 00:00:00 to: 2007-06-29 00:00:00\n",
      "Using model trained on 2007-06-29 00:00:00, Predict from: 2007-06-29 00:00:00 to: 2007-07-31 00:00:00\n",
      "Using model trained on 2007-07-31 00:00:00, Predict from: 2007-07-31 00:00:00 to: 2007-08-31 00:00:00\n",
      "Using model trained on 2007-08-31 00:00:00, Predict from: 2007-08-31 00:00:00 to: 2007-09-28 00:00:00\n",
      "Using model trained on 2007-09-28 00:00:00, Predict from: 2007-09-28 00:00:00 to: 2007-10-31 00:00:00\n",
      "Using model trained on 2007-10-31 00:00:00, Predict from: 2007-10-31 00:00:00 to: 2007-11-30 00:00:00\n",
      "Using model trained on 2007-11-30 00:00:00, Predict from: 2007-11-30 00:00:00 to: 2007-12-31 00:00:00\n",
      "Using model trained on 2007-12-31 00:00:00, Predict from: 2007-12-31 00:00:00 to: 2008-01-31 00:00:00\n",
      "Using model trained on 2008-01-31 00:00:00, Predict from: 2008-01-31 00:00:00 to: 2008-02-29 00:00:00\n",
      "Using model trained on 2008-02-29 00:00:00, Predict from: 2008-02-29 00:00:00 to: 2008-03-31 00:00:00\n",
      "Using model trained on 2008-03-31 00:00:00, Predict from: 2008-03-31 00:00:00 to: 2008-04-30 00:00:00\n",
      "Using model trained on 2008-04-30 00:00:00, Predict from: 2008-04-30 00:00:00 to: 2008-05-30 00:00:00\n",
      "Using model trained on 2008-05-30 00:00:00, Predict from: 2008-05-30 00:00:00 to: 2008-06-30 00:00:00\n",
      "Using model trained on 2008-06-30 00:00:00, Predict from: 2008-06-30 00:00:00 to: 2008-07-31 00:00:00\n",
      "Using model trained on 2008-07-31 00:00:00, Predict from: 2008-07-31 00:00:00 to: 2008-08-29 00:00:00\n",
      "Using model trained on 2008-08-29 00:00:00, Predict from: 2008-08-29 00:00:00 to: 2008-09-30 00:00:00\n",
      "Using model trained on 2008-09-30 00:00:00, Predict from: 2008-09-30 00:00:00 to: 2008-10-31 00:00:00\n",
      "Using model trained on 2008-10-31 00:00:00, Predict from: 2008-10-31 00:00:00 to: 2008-11-28 00:00:00\n",
      "Using model trained on 2008-11-28 00:00:00, Predict from: 2008-11-28 00:00:00 to: 2008-12-31 00:00:00\n",
      "Using model trained on 2008-12-31 00:00:00, Predict from: 2008-12-31 00:00:00 to: 2009-01-30 00:00:00\n",
      "Using model trained on 2009-01-30 00:00:00, Predict from: 2009-01-30 00:00:00 to: 2009-02-27 00:00:00\n",
      "Using model trained on 2009-02-27 00:00:00, Predict from: 2009-02-27 00:00:00 to: 2009-03-31 00:00:00\n",
      "Using model trained on 2009-03-31 00:00:00, Predict from: 2009-03-31 00:00:00 to: 2009-04-30 00:00:00\n",
      "Using model trained on 2009-04-30 00:00:00, Predict from: 2009-04-30 00:00:00 to: 2009-05-29 00:00:00\n",
      "Using model trained on 2009-05-29 00:00:00, Predict from: 2009-05-29 00:00:00 to: 2009-06-30 00:00:00\n",
      "Using model trained on 2009-06-30 00:00:00, Predict from: 2009-06-30 00:00:00 to: 2009-07-31 00:00:00\n",
      "Using model trained on 2009-07-31 00:00:00, Predict from: 2009-07-31 00:00:00 to: 2009-08-31 00:00:00\n",
      "Using model trained on 2009-08-31 00:00:00, Predict from: 2009-08-31 00:00:00 to: 2009-09-30 00:00:00\n",
      "Using model trained on 2009-09-30 00:00:00, Predict from: 2009-09-30 00:00:00 to: 2009-10-30 00:00:00\n",
      "Using model trained on 2009-10-30 00:00:00, Predict from: 2009-10-30 00:00:00 to: 2009-11-30 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model trained on 2009-11-30 00:00:00, Predict from: 2009-11-30 00:00:00 to: 2009-12-31 00:00:00\n",
      "Using model trained on 2009-12-31 00:00:00, Predict from: 2009-12-31 00:00:00 to: 2010-01-29 00:00:00\n",
      "Using model trained on 2010-01-29 00:00:00, Predict from: 2010-01-29 00:00:00 to: 2010-02-26 00:00:00\n",
      "Using model trained on 2010-02-26 00:00:00, Predict from: 2010-02-26 00:00:00 to: 2010-03-31 00:00:00\n",
      "Using model trained on 2010-03-31 00:00:00, Predict from: 2010-03-31 00:00:00 to: 2010-04-30 00:00:00\n",
      "Using model trained on 2010-04-30 00:00:00, Predict from: 2010-04-30 00:00:00 to: 2010-05-31 00:00:00\n",
      "Using model trained on 2010-05-31 00:00:00, Predict from: 2010-05-31 00:00:00 to: 2010-06-30 00:00:00\n",
      "Using model trained on 2010-06-30 00:00:00, Predict from: 2010-06-30 00:00:00 to: 2010-07-30 00:00:00\n",
      "Using model trained on 2010-07-30 00:00:00, Predict from: 2010-07-30 00:00:00 to: 2010-08-31 00:00:00\n",
      "Using model trained on 2010-08-31 00:00:00, Predict from: 2010-08-31 00:00:00 to: 2010-09-30 00:00:00\n",
      "Using model trained on 2010-09-30 00:00:00, Predict from: 2010-09-30 00:00:00 to: 2010-10-29 00:00:00\n",
      "Using model trained on 2010-10-29 00:00:00, Predict from: 2010-10-29 00:00:00 to: 2010-11-30 00:00:00\n",
      "Using model trained on 2010-11-30 00:00:00, Predict from: 2010-11-30 00:00:00 to: 2010-12-31 00:00:00\n",
      "Using model trained on 2010-12-31 00:00:00, Predict from: 2010-12-31 00:00:00 to: 2011-01-31 00:00:00\n",
      "Using model trained on 2011-01-31 00:00:00, Predict from: 2011-01-31 00:00:00 to: 2011-02-28 00:00:00\n",
      "Using model trained on 2011-02-28 00:00:00, Predict from: 2011-02-28 00:00:00 to: 2011-03-31 00:00:00\n",
      "Using model trained on 2011-03-31 00:00:00, Predict from: 2011-03-31 00:00:00 to: 2011-04-29 00:00:00\n",
      "Using model trained on 2011-04-29 00:00:00, Predict from: 2011-04-29 00:00:00 to: 2011-05-31 00:00:00\n",
      "Using model trained on 2011-05-31 00:00:00, Predict from: 2011-05-31 00:00:00 to: 2011-06-30 00:00:00\n",
      "Using model trained on 2011-06-30 00:00:00, Predict from: 2011-06-30 00:00:00 to: 2011-07-29 00:00:00\n",
      "Using model trained on 2011-07-29 00:00:00, Predict from: 2011-07-29 00:00:00 to: 2011-08-31 00:00:00\n",
      "Using model trained on 2011-08-31 00:00:00, Predict from: 2011-08-31 00:00:00 to: 2011-09-30 00:00:00\n",
      "Using model trained on 2011-09-30 00:00:00, Predict from: 2011-09-30 00:00:00 to: 2011-10-31 00:00:00\n",
      "Using model trained on 2011-10-31 00:00:00, Predict from: 2011-10-31 00:00:00 to: 2011-11-30 00:00:00\n",
      "Using model trained on 2011-11-30 00:00:00, Predict from: 2011-11-30 00:00:00 to: 2011-12-30 00:00:00\n",
      "Using model trained on 2011-12-30 00:00:00, Predict from: 2011-12-30 00:00:00 to: 2012-01-31 00:00:00\n",
      "Using model trained on 2012-01-31 00:00:00, Predict from: 2012-01-31 00:00:00 to: 2012-02-29 00:00:00\n",
      "Using model trained on 2012-02-29 00:00:00, Predict from: 2012-02-29 00:00:00 to: 2012-03-30 00:00:00\n",
      "Using model trained on 2012-03-30 00:00:00, Predict from: 2012-03-30 00:00:00 to: 2012-04-30 00:00:00\n",
      "Using model trained on 2012-04-30 00:00:00, Predict from: 2012-04-30 00:00:00 to: 2012-05-31 00:00:00\n",
      "Using model trained on 2012-05-31 00:00:00, Predict from: 2012-05-31 00:00:00 to: 2012-06-29 00:00:00\n",
      "Using model trained on 2012-06-29 00:00:00, Predict from: 2012-06-29 00:00:00 to: 2012-07-31 00:00:00\n",
      "Using model trained on 2012-07-31 00:00:00, Predict from: 2012-07-31 00:00:00 to: 2012-08-31 00:00:00\n",
      "Using model trained on 2012-08-31 00:00:00, Predict from: 2012-08-31 00:00:00 to: 2012-09-28 00:00:00\n",
      "Using model trained on 2012-09-28 00:00:00, Predict from: 2012-09-28 00:00:00 to: 2012-10-31 00:00:00\n",
      "Using model trained on 2012-10-31 00:00:00, Predict from: 2012-10-31 00:00:00 to: 2012-11-30 00:00:00\n",
      "Using model trained on 2012-11-30 00:00:00, Predict from: 2012-11-30 00:00:00 to: 2012-12-31 00:00:00\n",
      "Using model trained on 2012-12-31 00:00:00, Predict from: 2012-12-31 00:00:00 to: 2013-01-31 00:00:00\n",
      "Using model trained on 2013-01-31 00:00:00, Predict from: 2013-01-31 00:00:00 to: 2013-02-28 00:00:00\n",
      "Using model trained on 2013-02-28 00:00:00, Predict from: 2013-02-28 00:00:00 to: 2013-03-29 00:00:00\n",
      "Using model trained on 2013-03-29 00:00:00, Predict from: 2013-03-29 00:00:00 to: 2013-04-30 00:00:00\n",
      "Using model trained on 2013-04-30 00:00:00, Predict from: 2013-04-30 00:00:00 to: 2013-05-31 00:00:00\n",
      "Using model trained on 2013-05-31 00:00:00, Predict from: 2013-05-31 00:00:00 to: 2013-06-28 00:00:00\n",
      "Using model trained on 2013-06-28 00:00:00, Predict from: 2013-06-28 00:00:00 to: 2013-07-31 00:00:00\n",
      "Using model trained on 2013-07-31 00:00:00, Predict from: 2013-07-31 00:00:00 to: 2013-08-30 00:00:00\n",
      "Using model trained on 2013-08-30 00:00:00, Predict from: 2013-08-30 00:00:00 to: 2013-09-30 00:00:00\n",
      "Using model trained on 2013-09-30 00:00:00, Predict from: 2013-09-30 00:00:00 to: 2013-10-31 00:00:00\n",
      "Using model trained on 2013-10-31 00:00:00, Predict from: 2013-10-31 00:00:00 to: 2013-11-29 00:00:00\n",
      "Using model trained on 2013-11-29 00:00:00, Predict from: 2013-11-29 00:00:00 to: 2013-12-31 00:00:00\n",
      "Using model trained on 2013-12-31 00:00:00, Predict from: 2013-12-31 00:00:00 to: 2014-01-31 00:00:00\n",
      "Using model trained on 2014-01-31 00:00:00, Predict from: 2014-01-31 00:00:00 to: 2014-02-28 00:00:00\n",
      "Using model trained on 2014-02-28 00:00:00, Predict from: 2014-02-28 00:00:00 to: 2014-03-31 00:00:00\n",
      "Using model trained on 2014-03-31 00:00:00, Predict from: 2014-03-31 00:00:00 to: 2014-04-30 00:00:00\n",
      "Using model trained on 2014-04-30 00:00:00, Predict from: 2014-04-30 00:00:00 to: 2014-05-30 00:00:00\n",
      "Using model trained on 2014-05-30 00:00:00, Predict from: 2014-05-30 00:00:00 to: 2014-06-30 00:00:00\n",
      "Using model trained on 2014-06-30 00:00:00, Predict from: 2014-06-30 00:00:00 to: 2014-07-31 00:00:00\n",
      "Using model trained on 2014-07-31 00:00:00, Predict from: 2014-07-31 00:00:00 to: 2014-08-29 00:00:00\n",
      "Using model trained on 2014-08-29 00:00:00, Predict from: 2014-08-29 00:00:00 to: 2014-09-30 00:00:00\n",
      "Using model trained on 2014-09-30 00:00:00, Predict from: 2014-09-30 00:00:00 to: 2014-10-31 00:00:00\n",
      "Using model trained on 2014-10-31 00:00:00, Predict from: 2014-10-31 00:00:00 to: 2014-11-28 00:00:00\n",
      "Using model trained on 2014-11-28 00:00:00, Predict from: 2014-11-28 00:00:00 to: 2014-12-31 00:00:00\n",
      "Using model trained on 2014-12-31 00:00:00, Predict from: 2014-12-31 00:00:00 to: 2015-01-30 00:00:00\n",
      "Using model trained on 2015-01-30 00:00:00, Predict from: 2015-01-30 00:00:00 to: 2015-02-27 00:00:00\n",
      "Using model trained on 2015-02-27 00:00:00, Predict from: 2015-02-27 00:00:00 to: 2015-03-31 00:00:00\n",
      "Using model trained on 2015-03-31 00:00:00, Predict from: 2015-03-31 00:00:00 to: 2015-04-30 00:00:00\n",
      "Using model trained on 2015-04-30 00:00:00, Predict from: 2015-04-30 00:00:00 to: 2015-05-29 00:00:00\n",
      "Using model trained on 2015-05-29 00:00:00, Predict from: 2015-05-29 00:00:00 to: 2015-06-30 00:00:00\n",
      "Using model trained on 2015-06-30 00:00:00, Predict from: 2015-06-30 00:00:00 to: 2015-07-31 00:00:00\n",
      "Using model trained on 2015-07-31 00:00:00, Predict from: 2015-07-31 00:00:00 to: 2015-08-31 00:00:00\n",
      "Using model trained on 2015-08-31 00:00:00, Predict from: 2015-08-31 00:00:00 to: 2015-09-30 00:00:00\n",
      "Using model trained on 2015-09-30 00:00:00, Predict from: 2015-09-30 00:00:00 to: 2015-10-30 00:00:00\n",
      "Using model trained on 2015-10-30 00:00:00, Predict from: 2015-10-30 00:00:00 to: 2015-11-30 00:00:00\n",
      "Using model trained on 2015-11-30 00:00:00, Predict from: 2015-11-30 00:00:00 to: 2015-12-31 00:00:00\n",
      "Using model trained on 2015-12-31 00:00:00, Predict from: 2015-12-31 00:00:00 to: 2016-01-29 00:00:00\n",
      "Using model trained on 2016-01-29 00:00:00, Predict from: 2016-01-29 00:00:00 to: 2016-02-29 00:00:00\n",
      "Using model trained on 2016-02-29 00:00:00, Predict from: 2016-02-29 00:00:00 to: 2016-03-31 00:00:00\n",
      "Using model trained on 2016-03-31 00:00:00, Predict from: 2016-03-31 00:00:00 to: 2016-04-29 00:00:00\n",
      "Using model trained on 2016-04-29 00:00:00, Predict from: 2016-04-29 00:00:00 to: 2016-05-31 00:00:00\n",
      "Using model trained on 2016-05-31 00:00:00, Predict from: 2016-05-31 00:00:00 to: 2016-06-30 00:00:00\n",
      "Using model trained on 2016-06-30 00:00:00, Predict from: 2016-06-30 00:00:00 to: 2016-07-29 00:00:00\n",
      "Using model trained on 2016-07-29 00:00:00, Predict from: 2016-07-29 00:00:00 to: 2016-08-31 00:00:00\n",
      "Using model trained on 2016-08-31 00:00:00, Predict from: 2016-08-31 00:00:00 to: 2016-09-30 00:00:00\n",
      "Using model trained on 2016-09-30 00:00:00, Predict from: 2016-09-30 00:00:00 to: 2016-10-31 00:00:00\n",
      "Using model trained on 2016-10-31 00:00:00, Predict from: 2016-10-31 00:00:00 to: 2016-11-30 00:00:00\n",
      "Using model trained on 2016-11-30 00:00:00, Predict from: 2016-11-30 00:00:00 to: 2016-12-30 00:00:00\n",
      "Using model trained on 2016-12-30 00:00:00, Predict from: 2016-12-30 00:00:00 to: 2017-01-31 00:00:00\n",
      "Using model trained on 2017-01-31 00:00:00, Predict from: 2017-01-31 00:00:00 to: 2017-02-28 00:00:00\n",
      "Using model trained on 2017-02-28 00:00:00, Predict from: 2017-02-28 00:00:00 to: 2017-03-31 00:00:00\n",
      "Using model trained on 2017-03-31 00:00:00, Predict from: 2017-03-31 00:00:00 to: 2017-04-28 00:00:00\n",
      "Using model trained on 2017-04-28 00:00:00, Predict from: 2017-04-28 00:00:00 to: 2017-05-31 00:00:00\n",
      "Using model trained on 2017-05-31 00:00:00, Predict from: 2017-05-31 00:00:00 to: 2017-06-30 00:00:00\n",
      "Using model trained on 2017-06-30 00:00:00, Predict from: 2017-06-30 00:00:00 to: 2017-07-31 00:00:00\n",
      "Using model trained on 2017-07-31 00:00:00, Predict from: 2017-07-31 00:00:00 to: 2017-08-31 00:00:00\n",
      "Using model trained on 2017-08-31 00:00:00, Predict from: 2017-08-31 00:00:00 to: 2017-09-29 00:00:00\n",
      "Using model trained on 2017-09-29 00:00:00, Predict from: 2017-09-29 00:00:00 to: 2017-10-31 00:00:00\n",
      "Using model trained on 2017-10-31 00:00:00, Predict from: 2017-10-31 00:00:00 to: 2017-11-30 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model trained on 2017-11-30 00:00:00, Predict from: 2017-11-30 00:00:00 to: 2017-12-29 00:00:00\n",
      "Using model trained on 2017-12-29 00:00:00, Predict from: 2017-12-29 00:00:00 to: 2018-01-31 00:00:00\n",
      "Using model trained on 2018-01-31 00:00:00, Predict from: 2018-01-31 00:00:00 to: 2018-02-28 00:00:00\n",
      "Using model trained on 2018-02-28 00:00:00, Predict from: 2018-02-28 00:00:00 to: 2018-03-30 00:00:00\n",
      "Using model trained on 2018-03-30 00:00:00, Predict from: 2018-03-30 00:00:00 to: 2018-04-30 00:00:00\n",
      "Using model trained on 2018-04-30 00:00:00, Predict from: 2018-04-30 00:00:00 to: 2018-05-31 00:00:00\n",
      "Using model trained on 2018-05-31 00:00:00, Predict from: 2018-05-31 00:00:00 to: 2018-06-29 00:00:00\n",
      "Using model trained on 2018-06-29 00:00:00, Predict from: 2018-06-29 00:00:00 to: 2018-07-31 00:00:00\n",
      "Using model trained on 2018-07-31 00:00:00, Predict from: 2018-07-31 00:00:00 to: 2018-08-31 00:00:00\n",
      "Using model trained on 2018-08-31 00:00:00, Predict from: 2018-08-31 00:00:00 to: 2018-09-28 00:00:00\n",
      "Using model trained on 2018-09-28 00:00:00, Predict from: 2018-09-28 00:00:00 to: 2018-10-31 00:00:00\n",
      "Using model trained on 2018-10-31 00:00:00, Predict from: 2018-10-31 00:00:00 to: 2018-11-30 00:00:00\n",
      "Using model trained on 2018-11-30 00:00:00, Predict from: 2018-11-30 00:00:00 to: 2018-12-31 00:00:00\n",
      "Using model trained on 2018-12-31 00:00:00, Predict from: 2018-12-31 00:00:00 to: 2019-01-31 00:00:00\n",
      "Using model trained on 2019-01-31 00:00:00, Predict from: 2019-01-31 00:00:00 to: 2019-02-28 00:00:00\n",
      "Using model trained on 2019-02-28 00:00:00, Predict from: 2019-02-28 00:00:00 to: 2019-03-29 00:00:00\n",
      "Using model trained on 2019-03-29 00:00:00, Predict from: 2019-03-29 00:00:00 to: 2019-04-30 00:00:00\n",
      "Using model trained on 2019-04-30 00:00:00, Predict from: 2019-04-30 00:00:00 to: 2019-05-31 00:00:00\n",
      "Using model trained on 2019-05-31 00:00:00, Predict from: 2019-05-31 00:00:00 to: 2019-06-28 00:00:00\n",
      "Using model trained on 2019-06-28 00:00:00, Predict from: 2019-06-28 00:00:00 to: 2019-07-31 00:00:00\n",
      "Using model trained on 2019-07-31 00:00:00, Predict from: 2019-07-31 00:00:00 to: 2019-08-30 00:00:00\n",
      "Using model trained on 2019-08-30 00:00:00, Predict from: 2019-08-30 00:00:00 to: 2099-12-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "XGB_models,XGB_preds = walkforward_model(normalizedX,y,algo=XGBClassifier(*******))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgboost_full.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'xgboost_full.pkl'\n",
    "joblib.dump(XGB_models, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>xgb_full_preds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>STOCK_TICKER</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">2000-01-31</td>\n",
       "      <td>ABT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AGN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ALXN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AMGN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BAX</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">2019-09-30</td>\n",
       "      <td>LLY</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MRK</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PFE</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>REGN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SYK</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4627 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         xgb_full_preds\n",
       "date       STOCK_TICKER                \n",
       "2000-01-31 ABT                      0.0\n",
       "           AGN                      0.0\n",
       "           ALXN                     2.0\n",
       "           AMGN                     1.0\n",
       "           BAX                      0.0\n",
       "...                                 ...\n",
       "2019-09-30 LLY                      1.0\n",
       "           MRK                      1.0\n",
       "           PFE                      1.0\n",
       "           REGN                     1.0\n",
       "           SYK                      1.0\n",
       "\n",
       "[4627 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_entire = pd.DataFrame(data=XGB_preds).rename(columns={0: \"xgb_full_preds\"})\n",
    "df_entire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entire.to_excel(\"xgboost_full.xlsx\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_scorecard(y_pred,y_true):\n",
    "    \n",
    "    def make_df(y_pred,y_true):\n",
    "        y_pred.name = 'y_pred'\n",
    "        y_true.name = 'y_true'\n",
    "\n",
    "        df = pd.concat([y_pred,y_true],axis=1).dropna()\n",
    "        \n",
    "        df['is_correct'] = 0\n",
    "        df.loc[df.y_pred == df.y_true ,'is_correct'] = 1 # only registers 1 when prediction was made AND it was correct\n",
    "        df['is_incorrect'] = 0\n",
    "        df.loc[df.y_pred != df.y_true,'is_incorrect'] = 1 # only registers 1 when prediction was made AND it was wrong\n",
    "        df['is_correct_0'] = 0\n",
    "        df.loc[(df.y_pred == df.y_true) & (df.y_pred == 0) ,'is_correct_0'] = 1\n",
    "        df['is_incorrect_0'] = 0\n",
    "        df.loc[(df.y_pred != df.y_true) & (df.y_true == 0),'is_incorrect_0'] = 1\n",
    "        df['is_correct_1'] = 0\n",
    "        df.loc[(df.y_pred == df.y_true) & (df.y_pred == 1) ,'is_correct_1'] = 1\n",
    "        df['is_incorrect_1'] = 0\n",
    "        df.loc[(df.y_pred != df.y_true) & (df.y_true == 1),'is_incorrect_1'] = 1\n",
    "        df['is_correct_2'] = 0\n",
    "        df.loc[(df.y_pred == df.y_true) & (df.y_pred == 2) ,'is_correct_2'] = 1\n",
    "        df['is_incorrect_2'] = 0\n",
    "        df.loc[(df.y_pred != df.y_true) & (df.y_true == 2),'is_incorrect_2'] = 1\n",
    "        df['is_predicted'] = df.is_correct + df.is_incorrect\n",
    "        df['is_predicted_0'] = df.is_correct_0 + df.is_incorrect_0\n",
    "        df['is_predicted_1'] = df.is_correct_1 + df.is_incorrect_1\n",
    "        df['is_predicted_2'] = df.is_correct_2 + df.is_incorrect_2\n",
    "        return df\n",
    "    \n",
    "    df = make_df(y_pred,y_true)\n",
    "    \n",
    "    scorecard = pd.Series()\n",
    "    # building block metrics\n",
    "    scorecard.loc['accuracy'] = df.is_correct.sum()*1. / (df.is_predicted.sum()*1.)*100\n",
    "    scorecard.loc['accuracy_buy'] = df.is_correct_2.sum()*1. / (df.is_predicted_2.sum()*1.)*100\n",
    "    scorecard.loc['accuracy_hold'] = df.is_correct_1.sum()*1. / (df.is_predicted_1.sum()*1.)*100\n",
    "    scorecard.loc['accuracy_sell'] = df.is_correct_0.sum()*1. / (df.is_predicted_0.sum()*1.)*100\n",
    "    scorecard.loc['RSQ'] = r2_score(df.y_true,df.y_pred)\n",
    "    scorecard.loc['MAE'] = mean_absolute_error(df.y_true,df.y_pred)\n",
    "    scorecard.loc['MSE'] = mean_squared_error(df.y_true,df.y_pred)\n",
    "    scorecard.loc['MedAE'] = median_absolute_error(df.y_true,df.y_pred)\n",
    "    scorecard.loc['noise'] = df.y_pred.diff().abs().mean()\n",
    "    # derived metrics\n",
    "    scorecard.loc['y_true_chg'] = df.y_true.abs().mean()\n",
    "    scorecard.loc['y_pred_chg'] = df.y_pred.abs().mean()\n",
    "    \n",
    "    return scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy         80.981197\n",
       "accuracy_buy     68.911917\n",
       "accuracy_hold    89.172802\n",
       "accuracy_sell    76.724138\n",
       "RSQ               0.585418\n",
       "MAE               0.196023\n",
       "MSE               0.207694\n",
       "MedAE             0.000000\n",
       "noise             0.674233\n",
       "y_true_chg        0.999568\n",
       "y_pred_chg        0.980333\n",
       "Name: XGBoost, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_scorecard(y_pred=XGB_preds,y_true=y).rename('XGBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_over_time(y_pred,y_true):\n",
    "    df = pd.concat([y_pred,y_true],axis=1).dropna().reset_index().set_index('date')\n",
    "    scores = df.resample('BA').apply(lambda df: calc_scorecard(df[y_pred.name],df[y_true.name]))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_buy</th>\n",
       "      <th>accuracy_hold</th>\n",
       "      <th>accuracy_sell</th>\n",
       "      <th>RSQ</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MedAE</th>\n",
       "      <th>noise</th>\n",
       "      <th>y_true_chg</th>\n",
       "      <th>y_pred_chg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000-12-29</td>\n",
       "      <td>99.563319</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.082569</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.925439</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.004367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2001-12-31</td>\n",
       "      <td>96.250000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>97.500000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.765690</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2002-12-31</td>\n",
       "      <td>91.363636</td>\n",
       "      <td>83.636364</td>\n",
       "      <td>92.727273</td>\n",
       "      <td>96.363636</td>\n",
       "      <td>0.827273</td>\n",
       "      <td>0.086364</td>\n",
       "      <td>0.086364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.835616</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2003-12-31</td>\n",
       "      <td>92.500000</td>\n",
       "      <td>78.333333</td>\n",
       "      <td>95.833333</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589958</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>92.272727</td>\n",
       "      <td>85.454545</td>\n",
       "      <td>94.545455</td>\n",
       "      <td>94.545455</td>\n",
       "      <td>0.845455</td>\n",
       "      <td>0.077273</td>\n",
       "      <td>0.077273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.776256</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2005-12-30</td>\n",
       "      <td>87.083333</td>\n",
       "      <td>93.333333</td>\n",
       "      <td>94.166667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.129167</td>\n",
       "      <td>0.129167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.799163</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-12-29</td>\n",
       "      <td>85.833333</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.141667</td>\n",
       "      <td>0.141667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.769874</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>81.666667</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>81.666667</td>\n",
       "      <td>71.666667</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.195833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.878661</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.029167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>88.333333</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.170833</td>\n",
       "      <td>0.179167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.757322</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2009-12-31</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>63.333333</td>\n",
       "      <td>78.333333</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>0.391667</td>\n",
       "      <td>0.279167</td>\n",
       "      <td>0.304167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.029167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>80.454545</td>\n",
       "      <td>70.909091</td>\n",
       "      <td>86.363636</td>\n",
       "      <td>78.181818</td>\n",
       "      <td>0.609091</td>\n",
       "      <td>0.195455</td>\n",
       "      <td>0.195455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.762557</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2011-12-30</td>\n",
       "      <td>64.583333</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>58.333333</td>\n",
       "      <td>0.141667</td>\n",
       "      <td>0.379167</td>\n",
       "      <td>0.429167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.728033</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>67.916667</td>\n",
       "      <td>46.666667</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.677824</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>70.454545</td>\n",
       "      <td>43.636364</td>\n",
       "      <td>83.636364</td>\n",
       "      <td>70.909091</td>\n",
       "      <td>0.381818</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.309091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.529680</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>90.833333</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.358333</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.410042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>72.083333</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.518828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016-12-30</td>\n",
       "      <td>74.166667</td>\n",
       "      <td>43.333333</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.430962</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.887500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>79.166667</td>\n",
       "      <td>46.666667</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.502092</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>81.363636</td>\n",
       "      <td>70.909091</td>\n",
       "      <td>88.181818</td>\n",
       "      <td>78.181818</td>\n",
       "      <td>0.627273</td>\n",
       "      <td>0.186364</td>\n",
       "      <td>0.186364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.639269</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>83.707865</td>\n",
       "      <td>72.093023</td>\n",
       "      <td>91.111111</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.670370</td>\n",
       "      <td>0.162921</td>\n",
       "      <td>0.162921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.655367</td>\n",
       "      <td>0.988764</td>\n",
       "      <td>0.949438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             accuracy  accuracy_buy  accuracy_hold  accuracy_sell       RSQ  \\\n",
       "date                                                                          \n",
       "2000-12-29  99.563319    100.000000      99.082569     100.000000  0.991667   \n",
       "2001-12-31  96.250000     95.000000      97.500000      95.000000  0.925000   \n",
       "2002-12-31  91.363636     83.636364      92.727273      96.363636  0.827273   \n",
       "2003-12-31  92.500000     78.333333      95.833333     100.000000  0.850000   \n",
       "2004-12-31  92.272727     85.454545      94.545455      94.545455  0.845455   \n",
       "2005-12-30  87.083333     93.333333      94.166667      66.666667  0.741667   \n",
       "2006-12-29  85.833333     95.000000      91.666667      65.000000  0.716667   \n",
       "2007-12-31  81.666667     91.666667      81.666667      71.666667  0.608333   \n",
       "2008-12-31  83.333333     76.666667      88.333333      80.000000  0.641667   \n",
       "2009-12-31  73.333333     63.333333      78.333333      73.333333  0.391667   \n",
       "2010-12-31  80.454545     70.909091      86.363636      78.181818  0.609091   \n",
       "2011-12-30  64.583333     55.000000      72.500000      58.333333  0.141667   \n",
       "2012-12-31  67.916667     46.666667      86.666667      51.666667  0.083333   \n",
       "2013-12-31  70.454545     43.636364      83.636364      70.909091  0.381818   \n",
       "2014-12-31  65.000000     33.333333      90.833333      45.000000  0.250000   \n",
       "2015-12-31  72.083333     35.000000      90.000000      73.333333  0.416667   \n",
       "2016-12-30  74.166667     43.333333      90.000000      73.333333  0.458333   \n",
       "2017-12-29  79.166667     46.666667      91.666667      86.666667  0.583333   \n",
       "2018-12-31  81.363636     70.909091      88.181818      78.181818  0.627273   \n",
       "2019-12-31  83.707865     72.093023      91.111111      80.000000  0.670370   \n",
       "\n",
       "                 MAE       MSE  MedAE     noise  y_true_chg  y_pred_chg  \n",
       "date                                                                     \n",
       "2000-12-29  0.004367  0.004367    0.0  0.925439    1.000000    1.004367  \n",
       "2001-12-31  0.037500  0.037500    0.0  0.765690    1.000000    1.012500  \n",
       "2002-12-31  0.086364  0.086364    0.0  0.835616    1.000000    0.950000  \n",
       "2003-12-31  0.075000  0.075000    0.0  0.589958    1.000000    0.966667  \n",
       "2004-12-31  0.077273  0.077273    0.0  0.776256    1.000000    0.986364  \n",
       "2005-12-30  0.129167  0.129167    0.0  0.799163    1.000000    1.062500  \n",
       "2006-12-29  0.141667  0.141667    0.0  0.769874    1.000000    1.050000  \n",
       "2007-12-31  0.187500  0.195833    0.0  0.878661    1.000000    1.029167  \n",
       "2008-12-31  0.170833  0.179167    0.0  0.757322    1.000000    1.012500  \n",
       "2009-12-31  0.279167  0.304167    0.0  0.573222    1.000000    1.029167  \n",
       "2010-12-31  0.195455  0.195455    0.0  0.762557    1.000000    0.977273  \n",
       "2011-12-30  0.379167  0.429167    0.0  0.728033    1.000000    1.012500  \n",
       "2012-12-31  0.366667  0.458333    0.0  0.677824    1.000000    1.000000  \n",
       "2013-12-31  0.300000  0.309091    0.0  0.529680    1.000000    0.972727  \n",
       "2014-12-31  0.358333  0.375000    0.0  0.410042    1.000000    0.966667  \n",
       "2015-12-31  0.283333  0.291667    0.0  0.518828    1.000000    0.883333  \n",
       "2016-12-30  0.262500  0.270833    0.0  0.430962    1.000000    0.887500  \n",
       "2017-12-29  0.208333  0.208333    0.0  0.502092    1.000000    0.908333  \n",
       "2018-12-31  0.186364  0.186364    0.0  0.639269    1.000000    0.931818  \n",
       "2019-12-31  0.162921  0.162921    0.0  0.655367    0.988764    0.949438  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_over_time(XGB_preds,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_by_symbol(y_pred,y_true):\n",
    "    df = pd.concat([y_pred,y_true],axis=1).dropna()\n",
    "    scores = df.groupby(level='STOCK_TICKER').apply(lambda df: calc_scorecard(df[y_pred.name],df[y_true.name]))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Geoffrey/anaconda3/envs/FTDS/lib/python3.7/site-packages/ipykernel_launcher.py:38: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_buy</th>\n",
       "      <th>accuracy_hold</th>\n",
       "      <th>accuracy_sell</th>\n",
       "      <th>RSQ</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MedAE</th>\n",
       "      <th>noise</th>\n",
       "      <th>y_true_chg</th>\n",
       "      <th>y_pred_chg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STOCK_TICKER</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ABT</td>\n",
       "      <td>77.155172</td>\n",
       "      <td>7.692308</td>\n",
       "      <td>98.666667</td>\n",
       "      <td>43.478261</td>\n",
       "      <td>0.226083</td>\n",
       "      <td>0.228448</td>\n",
       "      <td>0.228448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108225</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.866379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AGN</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>98.809524</td>\n",
       "      <td>64.814815</td>\n",
       "      <td>0.478934</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116883</td>\n",
       "      <td>0.810345</td>\n",
       "      <td>0.849138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ALXN</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>85.620915</td>\n",
       "      <td>71.621622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054559</td>\n",
       "      <td>0.213043</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078603</td>\n",
       "      <td>1.652174</td>\n",
       "      <td>1.673913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AMGN</td>\n",
       "      <td>86.637931</td>\n",
       "      <td>35.714286</td>\n",
       "      <td>98.958333</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>0.203014</td>\n",
       "      <td>0.133621</td>\n",
       "      <td>0.133621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043290</td>\n",
       "      <td>1.068966</td>\n",
       "      <td>1.047414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BAX</td>\n",
       "      <td>83.620690</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>95.138889</td>\n",
       "      <td>72.857143</td>\n",
       "      <td>0.502258</td>\n",
       "      <td>0.163793</td>\n",
       "      <td>0.163793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125541</td>\n",
       "      <td>0.775862</td>\n",
       "      <td>0.775862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BIIB</td>\n",
       "      <td>79.310345</td>\n",
       "      <td>49.315068</td>\n",
       "      <td>98.648649</td>\n",
       "      <td>18.181818</td>\n",
       "      <td>0.199182</td>\n",
       "      <td>0.215517</td>\n",
       "      <td>0.232759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>1.267241</td>\n",
       "      <td>1.155172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BMRN</td>\n",
       "      <td>83.620690</td>\n",
       "      <td>59.259259</td>\n",
       "      <td>98.857143</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>0.332879</td>\n",
       "      <td>0.163793</td>\n",
       "      <td>0.163793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129870</td>\n",
       "      <td>0.987069</td>\n",
       "      <td>1.056034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BMY</td>\n",
       "      <td>85.344828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.272727</td>\n",
       "      <td>98.850575</td>\n",
       "      <td>0.156221</td>\n",
       "      <td>0.159483</td>\n",
       "      <td>0.185345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103896</td>\n",
       "      <td>0.262931</td>\n",
       "      <td>0.120690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CELG</td>\n",
       "      <td>87.931034</td>\n",
       "      <td>99.504950</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.071947</td>\n",
       "      <td>0.120690</td>\n",
       "      <td>0.120690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021645</td>\n",
       "      <td>1.870690</td>\n",
       "      <td>1.982759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DHR</td>\n",
       "      <td>71.120690</td>\n",
       "      <td>32.812500</td>\n",
       "      <td>97.014925</td>\n",
       "      <td>41.176471</td>\n",
       "      <td>0.256274</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>0.301724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160173</td>\n",
       "      <td>1.129310</td>\n",
       "      <td>1.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>GILD</td>\n",
       "      <td>76.293103</td>\n",
       "      <td>45.070423</td>\n",
       "      <td>94.155844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088571</td>\n",
       "      <td>0.237069</td>\n",
       "      <td>0.237069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099567</td>\n",
       "      <td>1.275862</td>\n",
       "      <td>1.176724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ILMN</td>\n",
       "      <td>71.040724</td>\n",
       "      <td>75.925926</td>\n",
       "      <td>80.645161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117893</td>\n",
       "      <td>0.316742</td>\n",
       "      <td>0.371041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086364</td>\n",
       "      <td>1.398190</td>\n",
       "      <td>1.479638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>INCY</td>\n",
       "      <td>71.551724</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>93.457944</td>\n",
       "      <td>17.142857</td>\n",
       "      <td>0.410510</td>\n",
       "      <td>0.284483</td>\n",
       "      <td>0.284483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160173</td>\n",
       "      <td>1.237069</td>\n",
       "      <td>1.245690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>JNJ</td>\n",
       "      <td>81.465517</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.417582</td>\n",
       "      <td>87.692308</td>\n",
       "      <td>0.387203</td>\n",
       "      <td>0.193966</td>\n",
       "      <td>0.211207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.487069</td>\n",
       "      <td>0.431034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LH</td>\n",
       "      <td>78.879310</td>\n",
       "      <td>49.152542</td>\n",
       "      <td>96.835443</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0.116597</td>\n",
       "      <td>0.224138</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077922</td>\n",
       "      <td>1.189655</td>\n",
       "      <td>1.155172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LLY</td>\n",
       "      <td>82.327586</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>63.768116</td>\n",
       "      <td>93.589744</td>\n",
       "      <td>0.301697</td>\n",
       "      <td>0.185345</td>\n",
       "      <td>0.202586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.186147</td>\n",
       "      <td>0.357759</td>\n",
       "      <td>0.258621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MRK</td>\n",
       "      <td>81.896552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.512195</td>\n",
       "      <td>91.095890</td>\n",
       "      <td>0.191582</td>\n",
       "      <td>0.193966</td>\n",
       "      <td>0.219828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129870</td>\n",
       "      <td>0.387931</td>\n",
       "      <td>0.306034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PFE</td>\n",
       "      <td>92.241379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.698113</td>\n",
       "      <td>98.876404</td>\n",
       "      <td>0.590548</td>\n",
       "      <td>0.077586</td>\n",
       "      <td>0.077586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.237069</td>\n",
       "      <td>0.176724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>REGN</td>\n",
       "      <td>78.017241</td>\n",
       "      <td>86.227545</td>\n",
       "      <td>57.812500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.097023</td>\n",
       "      <td>0.224138</td>\n",
       "      <td>0.232759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1.715517</td>\n",
       "      <td>1.741379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SYK</td>\n",
       "      <td>83.189655</td>\n",
       "      <td>53.061224</td>\n",
       "      <td>97.023810</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>0.288344</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.181034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.112554</td>\n",
       "      <td>1.146552</td>\n",
       "      <td>1.103448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy  accuracy_buy  accuracy_hold  accuracy_sell       RSQ  \\\n",
       "STOCK_TICKER                                                                    \n",
       "ABT           77.155172      7.692308      98.666667      43.478261  0.226083   \n",
       "AGN           87.500000     20.000000      98.809524      64.814815  0.478934   \n",
       "ALXN          80.000000     85.620915      71.621622       0.000000  0.054559   \n",
       "AMGN          86.637931     35.714286      98.958333       8.333333  0.203014   \n",
       "BAX           83.620690     33.333333      95.138889      72.857143  0.502258   \n",
       "BIIB          79.310345     49.315068      98.648649      18.181818  0.199182   \n",
       "BMRN          83.620690     59.259259      98.857143      16.666667  0.332879   \n",
       "BMY           85.344828      0.000000      47.272727      98.850575  0.156221   \n",
       "CELG          87.931034     99.504950      10.000000            NaN -0.071947   \n",
       "DHR           71.120690     32.812500      97.014925      41.176471  0.256274   \n",
       "GILD          76.293103     45.070423      94.155844       0.000000  0.088571   \n",
       "ILMN          71.040724     75.925926      80.645161       0.000000  0.117893   \n",
       "INCY          71.551724     66.666667      93.457944      17.142857  0.410510   \n",
       "JNJ           81.465517      0.000000      82.417582      87.692308  0.387203   \n",
       "LH            78.879310     49.152542      96.835443       6.666667  0.116597   \n",
       "LLY           82.327586     14.285714      63.768116      93.589744  0.301697   \n",
       "MRK           81.896552      0.000000      69.512195      91.095890  0.191582   \n",
       "PFE           92.241379      0.000000      71.698113      98.876404  0.590548   \n",
       "REGN          78.017241     86.227545      57.812500       0.000000 -0.097023   \n",
       "SYK           83.189655     53.061224      97.023810      26.666667  0.288344   \n",
       "\n",
       "                   MAE       MSE  MedAE     noise  y_true_chg  y_pred_chg  \n",
       "STOCK_TICKER                                                               \n",
       "ABT           0.228448  0.228448    0.0  0.108225    0.758621    0.866379  \n",
       "AGN           0.125000  0.125000    0.0  0.116883    0.810345    0.849138  \n",
       "ALXN          0.213043  0.239130    0.0  0.078603    1.652174    1.673913  \n",
       "AMGN          0.133621  0.133621    0.0  0.043290    1.068966    1.047414  \n",
       "BAX           0.163793  0.163793    0.0  0.125541    0.775862    0.775862  \n",
       "BIIB          0.215517  0.232759    0.0  0.121212    1.267241    1.155172  \n",
       "BMRN          0.163793  0.163793    0.0  0.129870    0.987069    1.056034  \n",
       "BMY           0.159483  0.185345    0.0  0.103896    0.262931    0.120690  \n",
       "CELG          0.120690  0.120690    0.0  0.021645    1.870690    1.982759  \n",
       "DHR           0.293103  0.301724    0.0  0.160173    1.129310    1.034483  \n",
       "GILD          0.237069  0.237069    0.0  0.099567    1.275862    1.176724  \n",
       "ILMN          0.316742  0.371041    0.0  0.086364    1.398190    1.479638  \n",
       "INCY          0.284483  0.284483    0.0  0.160173    1.237069    1.245690  \n",
       "JNJ           0.193966  0.211207    0.0  0.121212    0.487069    0.431034  \n",
       "LH            0.224138  0.250000    0.0  0.077922    1.189655    1.155172  \n",
       "LLY           0.185345  0.202586    0.0  0.186147    0.357759    0.258621  \n",
       "MRK           0.193966  0.219828    0.0  0.129870    0.387931    0.306034  \n",
       "PFE           0.077586  0.077586    0.0  0.095238    0.237069    0.176724  \n",
       "REGN          0.224138  0.232759    0.0  0.090909    1.715517    1.741379  \n",
       "SYK           0.172414  0.181034    0.0  0.112554    1.146552    1.103448  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_by_symbol(XGB_preds,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
